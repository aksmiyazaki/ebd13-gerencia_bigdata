%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Lachaise Assignment
% LaTeX Template
% Version 1.0 (26/6/2018)
%
% This template originates from:
% http://www.LaTeXTemplates.com
%
% Authors:
% Marion Lachaise & François Févotte
% Vel (vel@LaTeXTemplates.com)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass{article}
\usepackage{enumerate}
\usepackage{graphicx}
\input{structure.tex} % Include the file specifying the document structure and custom commands

%----------------------------------------------------------------------------------------
%	ASSIGNMENT INFORMATION
%----------------------------------------------------------------------------------------

\title{EBD13 Gerência de Dados e Computação em Nuvem} % Title of the assignment

\author{Alexandre Miyazaki\\ \texttt{aksmiyazaki@gmail.com}} % Author name and email address

\date{Universidade Federal do Rio Grande do Sul} % University, school and/or department name(s) and a date

%----------------------------------------------------------------------------------------

\begin{document}

\maketitle % Print the title

\section*{Objetivo do Trabalho} % Unnumbered section

O objetivo do trabalho era:

\begin{itemize}
\item Criar uma infraestrutura computacional em nuvem;
\item Realizar o deploy de um ambiente que seja capaz de analisar dados nesse ambiente;
\item Realizar uma análise simples.
\end{itemize}

Nas próximas seções estão os passos para atingir tais objetivos.


\section{Criando Infraestrutura} % Numbered section

Para criação da infraestrutura, foi escolhida a AWS, pois foi o ambiente no qual o professor realizou o laboratório.

\begin{figure}[h]
  \includegraphics[width=\linewidth]{img/machines_created.png}
  \caption{Máquinas criadas na \emph{cloud}.}
  \label{fig:fig_maq_criad}
\end{figure}

A Figura \ref{fig:fig_maq_criad} mostra a infraestrutura de máquinas. Foram criados 4 nós na AWS, sendo um deles o Mestre e os demais, escravos. 
A parte de segurança da rede na própria AWS foi negligenciada, deixando todas as portas abertas. Abaixo, a Figura \ref{fig:machine_config} mostra parte da configuração das máquinas na AWS.


\begin{figure}[h]
  \includegraphics[width=\linewidth]{img/machine_config.png}
  \caption{Parte da configuração dos nós.}
  \label{fig:machine_config}
\end{figure}

Antes de passarmos para a próxima Seção, precisamos conseguir acessar as máquinas criadas. O trabalho foi realizado
em uma máquina Linux, de forma que isso se torna fácil via ssh. A Figura \ref{fig:machine_access} mostra o processo para acessar a máquina via terminal.

\begin{figure}[h]
  \includegraphics[width=\linewidth]{img/machine_access.png}
  \caption{Acesso aos nós via ssh.}
  \label{fig:machine_access}
\end{figure}

\section{Deploy de Ambiente}

Iniciando o deploy do ambiente, foram instalados os pacotes requisitados. A Figura \ref{fig:package_install} exibe a linha de comando executada
para a instalação dos pacotes. Essa linha de comando foi executada em todos os nós (Master e 3 Slaves).

\begin{figure}[h]
  \includegraphics[width=\linewidth]{img/package_install.png}
  \caption{Linha de comando executada para instalação de pacotes.}
  \label{fig:package_install}
\end{figure}

Após esse processo, o Hadoop deve ser baixado e instalado nas máquinas. O comando exibido na Figura \ref{fig:hadoop_dl} foi executado em todos os nós da arquitetura.
Com o sistema baixado e descompactado, o ambiente está ok para continuarmos.

\begin{figure}[h]
  \includegraphics[width=\linewidth]{img/hadoop_download.png}
  \caption{Download do Hadoop.}
  \label{fig:hadoop_dl}
\end{figure}

\subsection{Executando o Spark no Ambiente}

Após a configuração, está na hora de executarmos o Master. Para isso, antes é necessário setar algumas variáveis de ambiente:


\begin{itemize}
\item SPARK\_LOCAL\_IP: é o IP onde da máquina vinculada ao Spark;
\item SPARK\_MASTER\_HOST: é o IP onde está rodando o nó Mestre.
\end{itemize}

Realizadas essas configurações, pode-se executar o Master com o script \emph{start-master.sh}. Ele gera um log ao executar, mostrado na Figura \ref{fig:spark_log}.

\begin{figure}[h]
  \includegraphics[width=\linewidth]{img/spark_log.png}
  \caption{Log do nó Master inicializado.}
  \label{fig:spark_log}
\end{figure}

Agora, vamos inicializar as instâncias dos Slaves. Para isso, precisamos executar o script \emph{start-slave.sh}, parametrizando o endereço do Master com a porta.
Realizado esse processo, o log do próprio Master acusa que os nós foram conectados, como mostra a Figura \ref{fig:env_ready}.

\begin{figure}[h]
  \includegraphics[width=\linewidth]{img/environment_ready.png}
  \caption{Mestre com os Slaves conectados.}
  \label{fig:env_ready}
\end{figure}

\subsection{Executando o PySpark}

\end{document}