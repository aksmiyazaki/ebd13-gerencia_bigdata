%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Lachaise Assignment
% LaTeX Template
% Version 1.0 (26/6/2018)
%
% This template originates from:
% http://www.LaTeXTemplates.com
%
% Authors:
% Marion Lachaise & François Févotte
% Vel (vel@LaTeXTemplates.com)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass{article}
\usepackage{enumerate}
\usepackage{graphicx}
\usepackage{hyperref}
\input{structure.tex} % Include the file specifying the document structure and custom commands

%----------------------------------------------------------------------------------------
%	ASSIGNMENT INFORMATION
%----------------------------------------------------------------------------------------

\title{EBD13 Gerência de Dados e Computação em Nuvem} % Title of the assignment

\author{Alexandre Miyazaki\\ \texttt{aksmiyazaki@gmail.com}} % Author name and email address

\date{Universidade Federal do Rio Grande do Sul} % University, school and/or department name(s) and a date

%----------------------------------------------------------------------------------------

\begin{document}

\maketitle % Print the title

\section*{Objetivo do Trabalho} % Unnumbered section

O objetivo do trabalho era:

\begin{itemize}
\item Criar uma infraestrutura computacional em nuvem;
\item Realizar o deploy de um ambiente que seja capaz de analisar dados nesse ambiente;
\item Realizar uma análise simples.
\end{itemize}

Nas próximas seções estão os passos para atingir tais objetivos.


\section{Criando Infraestrutura} % Numbered section

Para criação da infraestrutura, foi escolhida a AWS, pois foi o ambiente no qual o professor realizou o laboratório.

\begin{figure}[h]
  \includegraphics[width=\linewidth]{img/machines_created.png}
  \caption{Máquinas criadas na \emph{cloud}.}
  \label{fig:fig_maq_criad}
\end{figure}

A Figura \ref{fig:fig_maq_criad} mostra a infraestrutura de máquinas. Foram criados 4 nós na AWS, sendo um deles o Mestre e os demais, escravos. 
A parte de segurança da rede na própria AWS foi negligenciada, deixando todas as portas abertas. Abaixo, a Figura \ref{fig:machine_config} mostra parte da configuração das máquinas na AWS.


\begin{figure}[h]
  \includegraphics[width=\linewidth]{img/machine_config.png}
  \caption{Parte da configuração dos nós.}
  \label{fig:machine_config}
\end{figure}

Antes de passarmos para a próxima Seção, precisamos conseguir acessar as máquinas criadas. O trabalho foi realizado
em uma máquina Linux, de forma que isso se torna fácil via ssh. A Figura \ref{fig:machine_access} mostra o processo para acessar a máquina via terminal.

\begin{figure}[h]
  \includegraphics[width=\linewidth]{img/machine_access.png}
  \caption{Acesso aos nós via ssh.}
  \label{fig:machine_access}
\end{figure}

\section{Deploy de Ambiente}

Iniciando o deploy do ambiente, foram instalados os pacotes requisitados. A Figura \ref{fig:package_install} exibe a linha de comando executada
para a instalação dos pacotes. Essa linha de comando foi executada em todos os nós (Master e 3 Slaves).

\begin{figure}[h]
  \includegraphics[width=\linewidth]{img/package_install.png}
  \caption{Linha de comando executada para instalação de pacotes.}
  \label{fig:package_install}
\end{figure}

Após esse processo, o Hadoop deve ser baixado e instalado nas máquinas. O comando exibido na Figura \ref{fig:hadoop_dl} foi executado em todos os nós da arquitetura.
Com o sistema baixado e descompactado, o ambiente está ok para continuarmos.

\begin{figure}[h]
  \includegraphics[width=\linewidth]{img/hadoop_download.png}
  \caption{Download do Hadoop.}
  \label{fig:hadoop_dl}
\end{figure}

\subsection{Executando o Spark no Ambiente}

Após a configuração, está na hora de executarmos o Master. Para isso, antes é necessário setar algumas variáveis de ambiente:


\begin{itemize}
\item SPARK\_LOCAL\_IP: é o IP onde da máquina vinculada ao Spark;
\item SPARK\_MASTER\_HOST: é o IP onde está rodando o nó Mestre.
\end{itemize}

Realizadas essas configurações, pode-se executar o Master com o script \emph{start-master.sh}. Ele gera um log ao executar, mostrado na Figura \ref{fig:spark_log}.

\begin{figure}[h]
  \includegraphics[width=\linewidth]{img/spark_log.png}
  \caption{Log do nó Master inicializado.}
  \label{fig:spark_log}
\end{figure}

Agora, vamos inicializar as instâncias dos Slaves. Para isso, precisamos executar o script \emph{start-slave.sh}, parametrizando o endereço do Master com a porta.
Realizado esse processo, o log do próprio Master acusa que os nós foram conectados, como mostra a Figura \ref{fig:env_ready}.

\begin{figure}[h]
  \includegraphics[width=\linewidth]{img/environment_ready.png}
  \caption{Mestre com os Slaves conectados.}
  \label{fig:env_ready}
\end{figure}

\subsection{Fazendo o Deploy do Jupyter}

Neste trabalho, decidi por utilizar Python e PySpark (já como uma preparação para o trabalho final). Para isso, inicialmente fiz o Deploy do Jupyter.

Inicialmente, baixei e instalei o \href{https://www.anaconda.com/download/#linux}{Anaconda} todavia, por algum motivo, o Python ainda era reconhecido como o que já vem instalado no sistema. Ao dar um reboot na máquina, ele reconheceu o certo (e posteriormente, achei uma forma mais simples de fazer, usando o comando \empth{source .bashrc} (o Anaconda faz mudanças no arquivo .bashrc).

Feito isso, foram executados uma série de comandos e edição de arquivos de configuração para subir o Jupyter, eles podem ser visualizados \href{https://medium.com/@josemarcialportilla/getting-spark-python-and-jupyter-notebook-running-on-amazon-ec2-dec599e1c297}{neste link}. Acredito que fuja do escopo do trabalho detalhar essa parte, portanto fica o tutorial como registro.

Após a realização das configurações (vale salientar que uma delas é configuração de senha, e que o setup dele na Amazon foi menos \emph{plug-and-play} do que setar localmente), foi possível acessar o Jupyter remotamente, conforme mostra a Figura \ref{fig:acess_jupyter}.

\begin{figure}[h]
  \includegraphics[width=\linewidth]{img/jupyter_access.png}
  \caption{Acesso ao Jupyter Notebook.}
  \label{fig:acess_jupyter}
\end{figure}

\subsection{Configurando o PySpark}

Para rodar o Spark com Python, é necessário instalar a biblioteca Pyspark, além de declarar algumas variáveis de ambiente. Inicialmente, instalou-se o PySpark (Figura \ref{fig:pyspark_install}.

\begin{figure}[h]
  \includegraphics[width=\linewidth]{img/install_pyspark.png}
  \caption{Instalação do Pyspark.}
  \label{fig:pyspark_install}
\end{figure}

Após realizar essa instalação, as seguintes variáveis de ambiente foram configuradas:

\begin{itemize}
    \item export SPARK\_HOME='/home/admin/spark-2.1.0-bin-hadoop2.7'
    \item export PATH=\$SPARK\_HOME:\$PATH
    \item export PYTHONPATH=\$SPARK\_HOME/python:\$PYTHONPATH
\end{itemize}

Agora, partimos para a parte de carregar os dados e analisá-los.

\end{document}